(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{101:function(e,t,n){"use strict";n.d(t,"a",(function(){return b})),n.d(t,"b",(function(){return d}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=a.a.createContext({}),s=function(e){var t=a.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},b=function(e){var t=s(e.components);return a.a.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},m=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),b=s(n),m=r,d=b["".concat(i,".").concat(m)]||b[m]||u[m]||o;return n?a.a.createElement(d,l(l({ref:t},c),{},{components:n})):a.a.createElement(d,l({ref:t},c))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return a.a.createElement.apply(null,i)}return a.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},108:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/files/kubeflow_tutorials_5.3-d2702c9f055fa88dc7dd4cb0330cd6f8.zip"},70:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return l})),n.d(t,"rightToc",(function(){return p})),n.d(t,"default",(function(){return s}));var r=n(2),a=n(6),o=(n(0),n(101)),i={id:"kfp-tutorial",title:"Kubeflow Pipelines (KFP)"},l={unversionedId:"Kubeflow/user-tutorials/kfp-tutorial",id:"Kubeflow/user-tutorials/kfp-tutorial",isDocsHomePage:!1,title:"Kubeflow Pipelines (KFP)",description:"Running a basic Pipeline",source:"@site/docs/Kubeflow/user-tutorials/kubeflow-pipelines.md",slug:"/Kubeflow/user-tutorials/kfp-tutorial",permalink:"/mlops/docs/Kubeflow/user-tutorials/kfp-tutorial",editUrl:"https://github.com/nataliiaskopiuk/mlops/edit/master/docs/Kubeflow/user-tutorials/kubeflow-pipelines.md",version:"current",sidebar:"someSidebar",previous:{title:"GitHub Issue Summarization Example. Part 2",permalink:"/mlops/docs/Kubeflow/user-tutorials/gh-issue-sum-tutorial-p2"},next:{title:"User Access to Data in HDFS",permalink:"/mlops/docs/Kubeflow/user-tutorials/hdfs-access"}},p=[{value:"Running a basic Pipeline",id:"running-a-basic-pipeline",children:[]},{value:"Running Pipeline in Jupyter Notebook",id:"running-pipeline-in-jupyter-notebook",children:[]},{value:"Run Spark as a part of KFP",id:"run-spark-as-a-part-of-kfp",children:[]}],c={rightToc:p};function s(e){var t=e.components,i=Object(a.a)(e,["components"]);return Object(o.b)("wrapper",Object(r.a)({},c,i,{components:t,mdxType:"MDXLayout"}),Object(o.b)("h3",{id:"running-a-basic-pipeline"},"Running a basic Pipeline"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Open Kubeflow dashboard.")),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},"Go to Pipelines page.")),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},"Click the name of the sample, ",Object(o.b)("strong",{parentName:"li"},"[","Tutorial] DSL - Control structures"),".")),Object(o.b)("ol",{start:4},Object(o.b)("li",{parentName:"ol"},"Click ",Object(o.b)("strong",{parentName:"li"},"Create experiment")," and follow the prompts.")),Object(o.b)("ol",{start:5},Object(o.b)("li",{parentName:"ol"},"Create a run by clicking on the ",Object(o.b)("strong",{parentName:"li"},"Start")," button.")),Object(o.b)("ol",{start:6},Object(o.b)("li",{parentName:"ol"},"Click the name of the run on the ",Object(o.b)("strong",{parentName:"li"},"Experiments")," page.")),Object(o.b)("ol",{start:7},Object(o.b)("li",{parentName:"ol"},"Explore the graph and other aspects of your run by clicking on the components of the graph and the other UI elements.")),Object(o.b)("h3",{id:"running-pipeline-in-jupyter-notebook"},"Running Pipeline in Jupyter Notebook"),Object(o.b)("p",null,"Example from ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/kubeflow/pipelines/blob/master/samples/core/lightweight_component/lightweight_component.ipynb"}),"here"),". "),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"Create Jupyter notebook server.")),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},"Connect to the notebook and click to open a New Terminal.")),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"In the terminal clone ",Object(o.b)("inlineCode",{parentName:"p"},"kubeflow/pipelines")," repository: "),Object(o.b)("p",{parentName:"li"},Object(o.b)("inlineCode",{parentName:"p"},"$ git clone https://github.com/kubeflow/pipelines.git")))),Object(o.b)("p",null,Object(o.b)("em",{parentName:"p"},"Note:")," If using proxy, first run the bellow command: "),Object(o.b)("p",null,"   ",Object(o.b)("inlineCode",{parentName:"p"},"$ export https_proxy=<https_proxy_host>")),Object(o.b)("ol",{start:4},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Go back to the ",Object(o.b)("strong",{parentName:"p"},"Files")," tab and open a notebook: "),Object(o.b)("p",{parentName:"li"},Object(o.b)("inlineCode",{parentName:"p"},"pipelines/samples/core/lightweight_component/lightweight_component.ipynb")))),Object(o.b)("ol",{start:5},Object(o.b)("li",{parentName:"ol"},"Run the notebook step by step.")),Object(o.b)("ol",{start:6},Object(o.b)("li",{parentName:"ol"},"In the last step click on the links provided and check respective experiment and run are available in Pipelines UI.")),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},'"Experiment link here"')," opens the experiment created in the Pipelines UI."),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},'"Run link here"')," opens the run created in the Pipelines UI."),Object(o.b)("ol",{start:7},Object(o.b)("li",{parentName:"ol"},"Open ",Object(o.b)("strong",{parentName:"li"},"Experiments")," page in the ",Object(o.b)("strong",{parentName:"li"},"Pipelines")," dashboard. In ",Object(o.b)("strong",{parentName:"li"},"All Experiments")," tab expand ",Object(o.b)("strong",{parentName:"li"},"Default")," group and view pipeline graph and details per step by clicking on ","[","View pipeline] link.")),Object(o.b)("ol",{start:8},Object(o.b)("li",{parentName:"ol"},"In ",Object(o.b)("strong",{parentName:"li"},"All runs")," tab click on the name of the run to view ",Object(o.b)("strong",{parentName:"li"},"Graph"),", ",Object(o.b)("strong",{parentName:"li"},"Run output")," and ",Object(o.b)("strong",{parentName:"li"},"Config")," tabs. ")),Object(o.b)("h3",{id:"run-spark-as-a-part-of-kfp"},"Run Spark as a part of KFP"),Object(o.b)("p",null,"Upload the ",Object(o.b)("a",{target:"_blank",href:n(108).default},"kubeflow-tutorial.zip")," if you have not done that before."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},"In Kubeflow UI create a new Notebook Server.  ")),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},"Any of the default Jupyter images can be used. No specific properties or options are required. ")),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Connect to the created Notebook Server and open Python3 Notebook. ")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"In the created Notebook prepare the code for running Pipelines: "),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),'import kfp.dsl as dsl\nimport yaml\n\n@dsl.pipeline(\n    name = "Spark pipeline demo",\n    description = "Use saprk operator inside KF",\n) \n\ndef spark_pi_pipeline():\n    spark_yaml = yaml.safe_load(open("/home/jovyan/pyspark.yaml"))\n    deploy_step = dsl.ResourceOp(\n        name="spark-job",\n        k8s_resource=spark_yaml,\n        attribute_outputs={"name": "{.metadata.name}"})\n\nimport kfp\nkfp.Client().create_run_from_pipeline_func(spark_pi_pipeline, arguments={})\n')))),Object(o.b)("ol",{start:5},Object(o.b)("li",{parentName:"ol"},"In the root folder of the Jupyter notebook upload .yaml file with the code for spark job (",Object(o.b)("inlineCode",{parentName:"li"},"pyspark.yaml"),"). ")),Object(o.b)("ol",{start:6},Object(o.b)("li",{parentName:"ol"},"Create new notebook (PySpark, Python 3, etc.). Upload example code for Wordcount job (",Object(o.b)("inlineCode",{parentName:"li"},"spark-wc.yaml"),").")),Object(o.b)("p",null,Object(o.b)("em",{parentName:"p"},"Note:")," change namespace name, path to the file input.txt in maprfs (with any content) and spark.mapr.user.secret name to match existing values. "),Object(o.b)("ol",{start:7},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Login to the ECP Control Pane, open terminal and execute script to generate maprticket:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"$ kubectl exec -it tenantcli-0 -- su - <ldap_user_name> \nEnter password\n[<ldap_user_name>@tenantcli-0 mapr]$ ticketcreator.sh\nCreate a ticket for tenant user: [mapr]: <ldap_user_name>\nPlease provide '<ldap_user_name>'s password: [mapr]: <ldap_user_password>\n. \n. \n. \nPlease provide a name for your user secret: [mapr-user-secret-2430753274]: mapr-user-secret-spark-example\n")))),Object(o.b)("p",null,Object(o.b)("em",{parentName:"p"},"Note:")," Use the name of the created user secret in spark job code in previous step (example: ",Object(o.b)("inlineCode",{parentName:"p"},"mapr-user-secret-spark-example"),")."),Object(o.b)("ol",{start:8},Object(o.b)("li",{parentName:"ol"},"Run the code for Pipelines in the notebook.")),Object(o.b)("ol",{start:9},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"After the driver pod become ",Object(o.b)("inlineCode",{parentName:"p"},"Completed")," see result of example in logs: "),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"$ kubectl logs spark-wordcount-secure-driver -n <tenant_namespace> --tail=10\nuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n21/01/18 11:07:58 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n21/01/18 11:08:13 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n21/01/18 11:08:28 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\nspark: 1\n2: 3\nhello: 2\nmy: 1\nfrom: 1\n")))))}s.isMDXComponent=!0}}]);